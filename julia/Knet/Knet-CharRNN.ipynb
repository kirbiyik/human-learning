{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knet.KnetArray"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet\n",
    "Atype = gpu() >= 0 ? KnetArray : Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"4934845-element Array{UInt8,1}\", \"526731-element Array{UInt8,1}\", \"84-element Array{Char,1}\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(Knet.dir(\"data\",\"gutenberg.jl\"))\n",
    "trn,tst,chars = shakespeare()\n",
    "# summary(x) returns a string with a brief description. \n",
    "# By default returns string(typeof(x)), e.g. Int64.\n",
    "# mapping applies summary to other arguments to give a\n",
    "# brief look to variables, doesn't change anything.\n",
    "map(summary,(trn,tst,chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Char,1}:\n",
       " 'a'\n",
       " 'n'\n",
       " 'd'\n",
       " ' '\n",
       " 't'\n",
       " 'i'\n",
       " 'm'\n",
       " 'e'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 84 unique characters in the data and they are mapped to UInt8 values in 1:84.\n",
    "# The chars array can be used to recover the original text:\n",
    "chars[trn][end-97: end - 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCHSIZE = 256\n",
    "SEQLENGTH = 100\n",
    "\n",
    "function minibatch_rnn(data)\n",
    "    num_batch = div(length(data), BATCHSIZE)\n",
    "    # reshape full data to (B,num_batch) with contiguous rows\n",
    "    # \n",
    "    #x = reshape(data[1:num_batch * BATCHSIZE], num_batch, BATCHSIZE)'\n",
    "    x = reshape(data[1:num_batch * BATCHSIZE], BATCHSIZE, num_batch)\n",
    "    # split into (B,T) blocks\n",
    "    # Meaning of : x[:,1:num_batch-1], x[:,2:num_batch]\n",
    "    # Remember in char-rnn we were feeding next char as, sort of,\n",
    "    # label to the data. We sample at t, then compare with t+1. Then\n",
    "    # obtain loss.\n",
    "    minibatch(x[:,1:num_batch-1], x[:,2:num_batch], SEQLENGTH) \n",
    "end\n",
    "\n",
    "dtrain, dtest = minibatch_rnn(trn), minibatch_rnn(tst)\n",
    "map(length, (dtrain, dtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initmodel (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNTYPE = :lstm  # can be :lstm, :gru, :tanh, :relu\n",
    "NUMLAYERS = 1    # number of RNN layers\n",
    "INPUTSIZE = 168  # size of the input character embedding\n",
    "HIDDENSIZE = 334 # size of the hidden layers\n",
    "VOCABSIZE = 84   # number of unique characters in data\n",
    "\n",
    "# d... means varargs, 0 or more arguments\n",
    "# xavier directly passes varargs to rand in implementation\n",
    "function initmodel()\n",
    "    w(d...)=Atype(xavier(Float32,d...))\n",
    "    b(d...)=Atype(zeros(Float32,d...))\n",
    "    # r is rnn struct.\n",
    "    # w: single weight array that includes all matrices and biases for the RNN\n",
    "    r,wr = rnninit(INPUTSIZE,HIDDENSIZE,rnnType=RNNTYPE,numLayers=NUMLAYERS)\n",
    "    # input embedding matrix\n",
    "    wx = w(INPUTSIZE,VOCABSIZE)\n",
    "    # wy: hidden state to output\n",
    "    wy = w(VOCABSIZE,HIDDENSIZE)\n",
    "    by = b(VOCABSIZE,1)\n",
    "    return r,wr,wx,wy,by\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(ws, xs, hx, cx)\n",
    "    # ws expected to have this structure\n",
    "    r,wr,wx,wy,by = ws\n",
    "    # below embeds chars to vectors, wx is char embedding weights\n",
    "    x = wx[:,xs] # xs=(Batch,Time) x=(X,B,T)\n",
    "    # y=(H,B,T) hy=cy=(H,B,L)\n",
    "    y,hy,cy = rnnforw(r, wr, x, hx, cx, hy=true, cy=true)\n",
    "    ys = by.+wy*reshape(y,size(y,1),size(y,2)*size(y,3)) # ys=(H,B*T)\n",
    "    return ys, hy, cy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::gradfun) (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(w, x, y, h)\n",
    "    # h[1]-> hx, h[2]-> cx\n",
    "    py, hy, cy = predict(w, x, h...)\n",
    "    # In order AutoGrad to work we need getval somehow..\n",
    "    h[1], h[2] = getval(hy), getval(cy)\n",
    "    return nll(py, y)\n",
    "end\n",
    "\n",
    "# reports loss and calculates grads\n",
    "lossgradient = gradloss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(model, data, optim)\n",
    "    # rnn forwards assumes zero vector when hidden is nothing\n",
    "    hiddens = Any[nothing, nothing]\n",
    "    losses = []\n",
    "    for (x, y) in data\n",
    "        grads, current_loss = lossgradient(model, x, y, hiddens)\n",
    "        update!(model, grads, optim)\n",
    "        push!(losses, current_loss)\n",
    "    end\n",
    "    return mean(losses)\n",
    "end\n",
    "\n",
    "function test(model, data)\n",
    "    hiddens = Any[nothing, nothing]\n",
    "    losses = []\n",
    "    for (x, y) in data\n",
    "        current_loss = loss(model, x, y, hiddens)\n",
    "        push!(losses, current_loss)\n",
    "    end\n",
    "    return mean(losses)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.302084 seconds (1.89 M allocations: 221.551 MiB, 6.35% gc time)\n",
      "  0.529385 seconds (273.74 k allocations: 23.188 MiB, 1.02% gc time)\n",
      "(:epoch, 1, :trnppl, 25.741215f0, :tstppl, 23.52745f0)\n",
      "  6.928312 seconds (212.92 k allocations: 130.735 MiB, 9.79% gc time)\n",
      "  0.218703 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 2, :trnppl, 24.428959f0, :tstppl, 23.523182f0)\n",
      "  7.034200 seconds (213.68 k allocations: 130.746 MiB, 10.74% gc time)\n",
      "  0.305022 seconds (5.59 k allocations: 8.995 MiB, 27.51% gc time)\n",
      "(:epoch, 3, :trnppl, 24.41456f0, :tstppl, 23.513992f0)\n",
      "  6.909430 seconds (212.74 k allocations: 130.732 MiB, 9.69% gc time)\n",
      "  0.306212 seconds (5.97 k allocations: 9.001 MiB, 27.41% gc time)\n",
      "(:epoch, 4, :trnppl, 24.403934f0, :tstppl, 23.502546f0)\n",
      "  7.027001 seconds (214.80 k allocations: 130.763 MiB, 10.74% gc time)\n",
      "  0.221075 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 5, :trnppl, 24.395208f0, :tstppl, 23.492418f0)\n",
      "  7.067156 seconds (214.69 k allocations: 130.762 MiB, 10.71% gc time)\n",
      "  0.221311 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 6, :trnppl, 24.388275f0, :tstppl, 23.48418f0)\n",
      "  7.098070 seconds (214.69 k allocations: 130.762 MiB, 10.64% gc time)\n",
      "  0.306574 seconds (5.71 k allocations: 8.997 MiB, 27.19% gc time)\n",
      "(:epoch, 7, :trnppl, 24.382532f0, :tstppl, 23.477636f0)\n",
      "  7.007651 seconds (212.61 k allocations: 130.730 MiB, 9.59% gc time)\n",
      "  0.307510 seconds (6.09 k allocations: 9.003 MiB, 27.28% gc time)\n",
      "(:epoch, 8, :trnppl, 24.377464f0, :tstppl, 23.472397f0)\n",
      "  7.090163 seconds (214.67 k allocations: 130.761 MiB, 10.69% gc time)\n",
      "  0.222558 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 9, :trnppl, 24.373127f0, :tstppl, 23.468224f0)\n",
      "  7.095656 seconds (214.69 k allocations: 130.762 MiB, 10.57% gc time)\n",
      "  0.308691 seconds (5.47 k allocations: 8.994 MiB, 27.40% gc time)\n",
      "(:epoch, 10, :trnppl, 24.369154f0, :tstppl, 23.460005f0)\n",
      "  7.009565 seconds (212.85 k allocations: 130.733 MiB, 9.60% gc time)\n",
      "  0.307956 seconds (5.85 k allocations: 8.999 MiB, 27.06% gc time)\n",
      "(:epoch, 11, :trnppl, 24.363995f0, :tstppl, 23.440308f0)\n",
      "  7.085649 seconds (214.92 k allocations: 130.765 MiB, 10.68% gc time)\n",
      "  0.222481 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 12, :trnppl, 24.35752f0, :tstppl, 23.43724f0)\n",
      "  7.133145 seconds (214.69 k allocations: 130.762 MiB, 10.64% gc time)\n",
      "  0.221614 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 13, :trnppl, 24.352194f0, :tstppl, 23.425592f0)\n",
      "  7.106318 seconds (214.69 k allocations: 130.762 MiB, 10.53% gc time)\n",
      "  0.307885 seconds (5.59 k allocations: 8.995 MiB, 27.02% gc time)\n",
      "(:epoch, 14, :trnppl, 24.348896f0, :tstppl, 23.418467f0)\n",
      "  7.046642 seconds (212.74 k allocations: 130.732 MiB, 9.55% gc time)\n",
      "  0.309706 seconds (5.97 k allocations: 9.001 MiB, 27.16% gc time)\n",
      "(:epoch, 15, :trnppl, 24.346416f0, :tstppl, 23.41391f0)\n",
      "  7.120423 seconds (214.80 k allocations: 130.763 MiB, 10.62% gc time)\n",
      "  0.224554 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 16, :trnppl, 24.344427f0, :tstppl, 23.410606f0)\n",
      "  7.155721 seconds (214.69 k allocations: 130.762 MiB, 10.53% gc time)\n",
      "  0.224344 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 17, :trnppl, 24.34272f0, :tstppl, 23.408112f0)\n",
      "  7.211437 seconds (214.69 k allocations: 130.762 MiB, 10.55% gc time)\n",
      "  0.312541 seconds (5.71 k allocations: 8.997 MiB, 27.23% gc time)\n",
      "(:epoch, 18, :trnppl, 24.34113f0, :tstppl, 23.406204f0)\n",
      "  7.161767 seconds (212.61 k allocations: 130.730 MiB, 9.47% gc time)\n",
      "  0.312549 seconds (6.09 k allocations: 9.003 MiB, 27.23% gc time)\n",
      "(:epoch, 19, :trnppl, 24.339725f0, :tstppl, 23.404747f0)\n",
      "  7.268890 seconds (214.67 k allocations: 130.761 MiB, 10.49% gc time)\n",
      "  0.232447 seconds (3.64 k allocations: 8.966 MiB)\n",
      "(:epoch, 20, :trnppl, 24.338379f0, :tstppl, 23.403597f0)\n",
      "151.796318 seconds (6.45 M allocations: 2.843 GiB, 10.17% gc time)\n"
     ]
    }
   ],
   "source": [
    "# Let's train\n",
    "EPOCHS = 20\n",
    "model = initmodel()\n",
    "optim = optimizers(model, Adam)\n",
    "@time for epoch in 1:EPOCHS\n",
    "    @time trnloss = train(model,dtrain,optim) # ~18 seconds\n",
    "    @time tstloss = test(model,dtest)        # ~0.5 seconds\n",
    "    println((:epoch, epoch, :trnppl, exp(trnloss), :tstppl, exp(tstloss)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate(model, n)\n",
    "    function sample(y)\n",
    "        p, r = Atype(exp.(y - logsumexp(y))), rand()\n",
    "        for j=1:length(p)\n",
    "            (r -= p[j]) < 0 && return j\n",
    "        end\n",
    "    end\n",
    "    h,c = nothing,nothing\n",
    "    x = findfirst(chars,'\\n')\n",
    "    for i=1:n\n",
    "        y,h,c = predict(model,[x],h,c)\n",
    "        x = sample(y)\n",
    "        print(chars[x])\n",
    "    end\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__I've trained for a very short time, it's no surpise that it did not converged.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n t sgnhslvhi\n",
      "iis ir oc oNfwe yd ft  \n",
      "b\n",
      "Ie\n",
      " r\n",
      "eie \n",
      " e spoeetoI r ne  eenuo.c .t  d\n",
      "u?koo,u la h eoes  rso htnsee \n",
      "gdll\n",
      "oI e .a\n",
      "  tLoert lnypn AsaeA  iooDsa.tn'ymyli ,ennoiidlda msly eNWel blt[r heIu w\n",
      "skl Jm\n",
      "nh etrnesThthhdfoeeain R \n",
      "\n",
      "e y\n",
      "]   ,wimyoasr\n",
      " rt euaR\n",
      "r vsse aw!iooiehus vgh  eg\n",
      "nleersmhA de   e  ya ,Mss BTfi n a\n",
      " :t e   o oow\n",
      "t\n",
      "l-he y,  ebh ,hsn   \n",
      "Tiodht afiy,, eN.tdstisubohog  r o    c  a YtR s  eHh wei\n",
      "d eohylohdem  euektr \n",
      "m ni emyahshah\n",
      "  Tbetco Kihdhw'n lq\n"
     ]
    }
   ],
   "source": [
    "generate(model,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91msyntax: extra token \"status\" after end of expression\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91msyntax: extra token \"status\" after end of expression\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.3 AI",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
